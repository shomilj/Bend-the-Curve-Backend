{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Bing API to Collect Coronavirus Statistics\n",
    "\n",
    "This is the backend for \"Bend the Curve\" - https://github.com/shomilj/Bend-the-Curve-iOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be honest, I'm not sure if these headers are necessary! Regardless, I'm not sure if these are official API's â€“ I pulled them from https://www.bing.com/covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'authority': 'www.bing.com',\n",
    "    'pragma': 'no-cache',\n",
    "    'cache-control': 'no-cache',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'accept': '*/*',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'referer': 'https://www.bing.com/covid',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('IG', '140FBA510971427188AF4078EE911038'),\n",
    ")\n",
    "\n",
    "metadata = requests.get('https://www.bing.com/covid/data', headers=headers, params=params).json()\n",
    "headers = {\n",
    "    'authority': 'www.bing.com',\n",
    "    'pragma': 'no-cache',\n",
    "    'cache-control': 'no-cache',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'accept': '*/*',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'referer': 'https://www.bing.com/covid',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "}\n",
    "\n",
    "graphdata = requests.get('https://www.bing.com/covid/graphdata', headers=headers).json()\n",
    "targets = list(graphdata.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*graphdata* contains data needed to generate the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'confirmed': 1, 'fatal': 0, 'recovered': 0, 'date': '2020-01-24'},\n",
       " {'confirmed': 2, 'fatal': 0, 'recovered': 0, 'date': '2020-01-25'},\n",
       " {'confirmed': 2, 'fatal': 0, 'recovered': 0, 'date': '2020-01-26'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphdata['unitedstates'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*metadata* is a tree-like structure containing regions and subregions, with data associated with each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'displayName', 'areas', 'totalConfirmed', 'totalDeaths', 'totalRecovered', 'lastUpdated'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse the tree-like structure into something more usable. *Regions* contains a list of key-metadata pairs (metadata = numConfirmed, numDeaths, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = {}\n",
    "def parse(d, parent='Global'):\n",
    "    try:\n",
    "        areas = d.pop('areas')\n",
    "    except:\n",
    "        areas = []\n",
    "    regions[d.get('id')] = d\n",
    "    [parse(a, d.get('displayName')) for a in areas]\n",
    "parse(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'unitedstates',\n",
       " 'displayName': 'United States',\n",
       " 'totalConfirmed': 48855,\n",
       " 'totalDeaths': 593,\n",
       " 'totalRecovered': 333,\n",
       " 'lastUpdated': '2020-03-24T16:46:39.014Z',\n",
       " 'lat': 39.495914459228516,\n",
       " 'long': -98.98998260498047,\n",
       " 'parentId': 'world'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions['unitedstates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a safediv function to avoid division by zero errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safediv(a, b):\n",
    "    try:\n",
    "        return round(100 * ((a - b) / b))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each target region, extract all relevant statistics and graph data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploads = {}\n",
    "\n",
    "for target in targets:\n",
    "    meta = regions.get(target)\n",
    "    if meta == None:\n",
    "        continue\n",
    "    \n",
    "    td = regions.get(target).get(\"totalDeaths\")\n",
    "    tr = regions.get(target).get(\"totalRecovered\")\n",
    "    tc = regions.get(target).get(\"totalConfirmed\")\n",
    "    \n",
    "    if td == None: td = graphdata[target][-1].get('fatal')\n",
    "    if tr == None: tr = graphdata[target][-1].get('recovered')\n",
    "    if tc == None: tc = graphdata[target][-1].get('confirmed')\n",
    "    dates = [r.get('date') for r in graphdata[target]] + [\"Today\"]\n",
    "    deaths = [r.get('fatal') for r in graphdata[target]] + [td]\n",
    "    confirmed = [r.get('confirmed') for r in graphdata[target]] + [tc]\n",
    "    recovered = [r.get('recovered') for r in graphdata[target]] + [tr]\n",
    "\n",
    "    \n",
    "    if len(dates) > 12:\n",
    "        stats = {\n",
    "            'oneDayPercent': safediv(tc, confirmed[-2]),\n",
    "            'fiveDayPercent': safediv(tc, confirmed[-7]),\n",
    "            'tenDayPercent':  safediv(tc, confirmed[-12]),\n",
    "            'oneDayNum': tc - confirmed[-2],\n",
    "            'fiveDayNum': tc - confirmed[-7],\n",
    "            'tenDayNum': tc - confirmed[-12],\n",
    "            'confirmedCount': tc\n",
    "        }\n",
    "    else:\n",
    "        stats = {'oneDayPercent': 0,\n",
    "                'fiveDayPercent': 0,\n",
    "                'tenDayPercent': 0,\n",
    "                'oneDayNum': 0,\n",
    "                'fiveDayNum': 0,\n",
    "                'tenDayNum': 0,\n",
    "                'confirmedCount': 0}\n",
    "    \n",
    "    try:\n",
    "        parent = regions.get(meta.get('parentId')).get('displayName')\n",
    "    except:\n",
    "        parent = 'Global'\n",
    "    \n",
    "    if parent == \"Italy\": continue\n",
    "        \n",
    "    upload = {\n",
    "        'country': parent,\n",
    "        'lat': meta.get('lat'),\n",
    "        'lon': meta.get('long'),\n",
    "        'region': meta.get('displayName'),\n",
    "        'timeSeriesKeys': ['Confirmed', 'Deaths', 'Recovered'],\n",
    "        'timeSeriesX': dates,\n",
    "        'timeSeriesY': {\n",
    "            'Confirmed': confirmed,\n",
    "            'Deaths': deaths,\n",
    "            'Recovered': recovered\n",
    "        },\n",
    "        'oneDayPercent': []\n",
    "    }\n",
    "    upload.update(stats)\n",
    "    if upload['country'] == 'Global' and upload.get('region') != None:\n",
    "        upload['country'] = upload['region']\n",
    "    uploads[target] = upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, *uploads* contains the data needed for the app to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'United States', 'lat': 39.495914459228516, 'lon': -98.98998260498047, 'region': 'United States', 'timeSeriesKeys': ['Confirmed', 'Deaths', 'Recovered'], 'timeSeriesX': ['2020-01-24', '2020-01-25', '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29', '2020-01-30', '2020-01-31', '2020-02-01', '2020-02-02', '2020-02-03', '2020-02-04', '2020-02-05', '2020-02-06', '2020-02-07', '2020-02-08', '2020-02-09', '2020-02-10', '2020-02-11', '2020-02-12', '2020-02-13', '2020-02-14', '2020-02-15', '2020-02-16', '2020-02-17', '2020-02-18', '2020-02-19', '2020-02-20', '2020-02-21', '2020-02-22', '2020-02-23', '2020-02-24', '2020-02-25', '2020-02-26', '2020-02-27', '2020-02-28', '2020-02-29', '2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', '2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13', '2020-03-14', '2020-03-15', '2020-03-16', '2020-03-17', '2020-03-18', '2020-03-19', '2020-03-20', '2020-03-21', '2020-03-22', '2020-03-23', 'Today'], 'timeSeriesY': {'Confirmed': [1, 2, 2, 5, 5, 5, 5, 6, 7, 8, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 35, 35, 35, 53, 53, 59, 59, 62, 62, 62, 64, 108, 129, 148, 213, 213, 213, 472, 696, 987, 1264, 1678, 1678, 4567, 6349, 9273, 13726, 19393, 25772, 33889, 43874, 48855], 'Deaths': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 9, 10, 11, 11, 11, 19, 25, 29, 36, 41, 41, 85, 98, 150, 201, 256, 311, 428, 558, 593], 'Recovered': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 73, 17, 106, 108, 125, 176, 179, 178, 333]}, 'oneDayPercent': 11, 'fiveDayPercent': 427, 'tenDayPercent': 3765, 'oneDayNum': 4981, 'fiveDayNum': 39582, 'tenDayNum': 47591, 'confirmedCount': 48855}\n"
     ]
    }
   ],
   "source": [
    "print(uploads['unitedstates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Firebase/Firestore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The app uses a Firebase/Firestore backend. Let's upload our data to that backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firebase_admin import firestore, credentials\n",
    "import firebase_admin\n",
    "try:\n",
    "    cred = credentials.Certificate('/Users/shomil/Documents/ServerKeys/ncov19.json')\n",
    "    firebase_admin.initialize_app(cred)\n",
    "except Exception as e:\n",
    "    try:\n",
    "        firebase_admin.initialize_app()\n",
    "    except Exception as f:\n",
    "        print(\"Already initialized!\")\n",
    "        print(e, f)\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed upload!\n"
     ]
    }
   ],
   "source": [
    "batch = db.batch()\n",
    "count = 0\n",
    "for k, v in uploads.items():\n",
    "    batch.set(db.collection('statistics').document(k), v)\n",
    "    count += 1\n",
    "    if count == 200:\n",
    "        batch.commit()\n",
    "        count = 0\n",
    "batch.commit()\n",
    "print(\"Completed upload!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def delete_all():\n",
    "#     batch = db.batch()\n",
    "#     def delete_collection(coll_ref, batch_size):\n",
    "#         docs = coll_ref.limit(batch_size).stream()\n",
    "#         deleted = 0\n",
    "\n",
    "#         for doc in docs:\n",
    "#             print(u'Deleting doc {} => {}'.format(doc.id, doc.to_dict()))\n",
    "#             batch.delete(doc.reference)\n",
    "#             deleted = deleted + 1\n",
    "\n",
    "#         if deleted >= batch_size:\n",
    "#             batch.commit()\n",
    "#             return delete_collection(coll_ref, batch_size)\n",
    "#     delete_collection(db.collection('statistics'), 100)\n",
    "#     batch.commit()\n",
    "#delete_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
